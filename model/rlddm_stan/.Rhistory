library("rstan", lib.loc="C:/Program Files/R/R-3.5.2/library")
library("StanHeaders", lib.loc="C:/Program Files/R/R-3.5.2/library")
library("StanHeaders", lib.loc="\\\\idnetapp-homes3.uzh.ch/phalle$/Documents/R/win-library/3.5")
output1 = gng_m1(data=dataPath, niter=20, nwarmup=5, nchain=4, ncore=4)
library("hBayesDM", lib.loc="C:/Program Files/R/R-3.5.2/library")
output1 = gng_m1(data=dataPath, niter=20, nwarmup=5, nchain=4, ncore=4)
install.packages("StanHeaders", lib="C:\\Program Files\\R\\R-3.5.2\\library")
install.packages("StanHeaders", lib = "C:\\Program Files\\R\\R-3.5.2\\library")
library("StanHeaders", lib.loc="C:/Program Files/R/R-3.5.2/library")
library("hBayesDM")
dataPath = system.file("extdata/gng_exampleData.txt", package="hBayesDM")
output1 = gng_m1(data=dataPath, niter=20, nwarmup=5, nchain=4, ncore=4)
.libPaths()
# output may look like this
#[1] "\\\\idnetapp-homes3.uzh.ch/phalle$/Documents/R/win-library/3.5"
#[2] "C:/Program Files/R/R-3.5.2/library"
assign(".lib.loc", "C:/Program Files/R/R-3.5.2/library", envir = environment(.libPaths))
#install.packages("rstan", lib="C:\\Program Files\\R\\R-3.5.2\\library")
#install.packages("StanHeaders", lib="C:\\Program Files\\R\\R-3.5.2\\library")
#install.packages("rstantools", lib="C:\\Program Files\\R\\R-3.5.2\\library")
#install.packages("hBayesDM", lib="C:\\Program Files\\R\\R-3.5.2\\library")
#install.packages("Rcpp", lib="C:\\Program Files\\R\\R-3.5.2\\library")
# after successful installation, load required packages
library("StanHeaders", lib.loc="C:/Program Files/R/R-3.5.2/library")
library("rstan", lib.loc="C:/Program Files/R/R-3.5.2/library")
library("Rcpp", lib.loc="C:/Program Files/R/R-3.5.2/library")
library("hBayesDM", lib.loc="C:/Program Files/R/R-3.5.2/library")
dataPath = "N:/studies/AllRead/Feedback learning/ddmodeling/children_abmp_fb_as_choice"
ddm_model_abmp_adults = choiceRT_ddm(
paste(dataPath, "model_input_abmp_children_190402.txt", sep="/"), niter=4000, nwarmup=1000, nchain=4, ncore=4, inits="fixed",
RTbound=0.05)
X <- c(11,12,13,14,21,22,23,24,31,32,33,34)
sample(X)
X <- c(11,12,13,14,21,22,23,24,31,32,33,34,11,12,13,14,21,22,23,24,31,32,33,34,11,12,13,14,21,22,23,24,31,32,33,34)
sample(X)
length(X)
sample(X)
sample(X)
sample(X)
sample(X)
sample(X)
X <- c(rep(112,113,121,131,221,223,212,232,331,332,313,323),3)
X
X <- rep(c(112,113,121,131,221,223,212,232,331,332,313,323),3)
X
length(X)
sample(X)
sample(X)
sample(X)
sample(X)
sample(X)
sample(X)
sample(X)
install.packages("RWiener")
library(RWiener)
stim <- c(112,121,113,131,114,141,221,212,223,232,224,242,331,313,332,323,334,343)
length(stim)
stim <- rep(stim,2)
stim
sample(stim,replace=FALSE)
sample(stim,replace=FALSE)
sample(stim,replace=FALSE)
sample(stim,replace=FALSE)
sample(stim,replace=FALSE)
sample(stim,replace=FALSE)
install.packages("rtdists", lib="C:/Program Files/R/R-3.5.2/library")
require(rtdist)
require(rtdists)
example(Diffusion)
library(RWiener)
library(ggplot2)
#rwiener(n, alpha,tau,beta,delta)
#restrictions: 0 < β < 1, α > 0, τ > 0
dat <- rwiener(20,0.5,1,0.5,0.5)
ggplot(dat) + geom_histogram() + aes(x=q, fil=)
ggplot(dat) + geom_histogram() + aes(x=resp)
ggplot(dat) + geom_histogram() + aes(x=resp)
ggplot(dat) + geom_histograms(stat="count") + aes(x=resp)
ggplot(dat) + geom_histogram(stat="count") + aes(x=resp)
ggplot(dat) + geom_histogram() + aes(x=q, fill=resp)
ggplot(dat) + geom_smooth() + aes(x=q, fill=resp)
ggplot(dat) + geom_density() + aes(x=q, fill=resp)
wiener_plot(dat)
#rwiener(n, alpha,tau,beta,delta)
#restrictions: 0 < β < 1, α > 0, τ > 0
dat <- rwiener(20,2,0.1,0.5,0.5)
wiener_plot(dat)
#rwiener(n, alpha,tau,beta,delta)
#restrictions: 0 < β < 1, α > 0, τ > 0
dat <- rwiener(20,2,0.1,0.5,0.6)
wiener_plot(dat)
#rwiener(n, alpha,tau,beta,delta)
#restrictions: 0 < β < 1, α > 0, τ > 0
dat <- rwiener(20,3,0.1,0.5,0.6)
wiener_plot(dat)
#rwiener(n, alpha,tau,beta,delta)
#restrictions: 0 < β < 1, α > 0, τ > 0
dat <- rwiener(20,2.5,0.1,0.5,0.6)
wiener_plot(dat)
#rwiener(n, alpha,tau,beta,delta)
#restrictions: 0 < β < 1, α > 0, τ > 0
dat <- rwiener(20,2.5,0.1,0.5,0.7)
wiener_plot(dat)
#rwiener(n, alpha,tau,beta,delta)
#restrictions: 0 < β < 1, α > 0, τ > 0
dat <- rwiener(20,2.5,0.1,0.5,0.6)
wiener_plot(dat)
#rwiener(n, alpha,tau,beta,delta)
#restrictions: 0 < β < 1, α > 0, τ > 0
dat <- rwiener(20,2.,0.1,0.5,0.6)
wiener_plot(dat)
.libPaths()
assign(".lib.loc", "C:/Program Files/R/R-3.5.2/library", envir = environment(.libPaths))
#install.packages("rstan", lib="C:\\Program Files\\R\\R-3.5.2\\library")
#install.packages("StanHeaders", lib="C:\\Program Files\\R\\R-3.5.2\\library")
#install.packages("rstantools", lib="C:\\Program Files\\R\\R-3.5.2\\library")
#install.packages("hBayesDM", lib="C:\\Program Files\\R\\R-3.5.2\\library")
#install.packages("Rcpp", lib="C:\\Program Files\\R\\R-3.5.2\\library")
# after successful installation, load required packages
library("StanHeaders", lib.loc="C:/Program Files/R/R-3.5.2/library")
library("rstan", lib.loc="C:/Program Files/R/R-3.5.2/library")
library("Rcpp", lib.loc="C:/Program Files/R/R-3.5.2/library")
library("hBayesDM", lib.loc="C:/Program Files/R/R-3.5.2/library")
### data loading and preprocessing
path <- dirname(rstudioapi::getActiveDocumentContext()$path)
model_path <- paste0(path,"/rlddm_invlog.stan")
data_path <- paste0(path,"/test_input.txt")
setwd(path)
library("Rcpp", lib.loc="C:/Program Files/R/R-3.5.2/library")
install.packages("Rcpp")
# after successful installation, load required packages
library("StanHeaders", lib.loc="C:/Program Files/R/R-3.5.2/library")
library("rstan", lib.loc="C:/Program Files/R/R-3.5.2/library")
install.packages("ggplot2")
library("Rcpp", lib.loc="C:/Program Files/R/R-3.5.2/library")
library("hBayesDM", lib.loc="C:/Program Files/R/R-3.5.2/library")
path <- dirname(rstudioapi::getActiveDocumentContext()$path)
model_path <- paste0(path,"/rlddm_invlog.stan")
data_path <- paste0(path,"/test_input.txt")
setwd(path)
raw_data <- data.table::fread(file = data_path, header = TRUE, sep = "\t", data.table = TRUE,
fill = TRUE, stringsAsFactors = TRUE, logical01 = FALSE)
raw_data <- cbind(rep(substr(data_path,1,12),dim(raw_data)[1]),raw_data)
#D<-D[D$resp!=0,] # remove 'too slow ' responses
### Rename and transform some columns
colnames(raw_data)[1] <- "subjID"
raw_data$rt <- raw_data$rt/1000
names(raw_data)[names(raw_data)=="rt"] <- "RT"
# automatically filter missed responses (since RT = 0)
raw_data <- raw_data[which(raw_data$RT > 0.15),]
raw_data$subjID = rep('01',nrow(raw_data))
# fb = 0 incorrect, fb = 1 correct, (fb = 2 missed)
names(raw_data)[names(raw_data)=="fb"] <- "correct"
## prepare data for jags
#raw_data$row <- seq.int(nrow(raw_data))
DT_trials <- raw_data[, .N, by = "subjID"]
subjs     <- DT_trials$subjID
n_subj    <- length(subjs)
# get minRT
minRT <- with(raw_data, aggregate(RT, by = list(y = subjID), FUN = min)[["x"]])
ifelse(is.null(dim(minRT)),minRT<-as.array(minRT))
# assign new trial number for excluded decisions
for (subj in subjs){
sub <- which(raw_data$subjID==subj)
raw_data[sub,]$trial <- seq.int(nrow(raw_data[sub,]))
}
# first is Sx1 matrix identifying all first trials of a subject for each choice
first <- which(raw_data$trial==1)
# if N=1 transform int to 1-d array
ifelse(is.null(dim(first)),first<-as.array(first))
# last is a Sx1 matrix identifying all last trials of a subject for each choice
last <- as.integer(first + DT_trials$N - 1)
ifelse(is.null(dim(last)),last<-as.array(last))
# incorrect is the inverse vector of choice and is needed to update the ev for the non-choices
raw_data$incorrect <- as.integer(ifelse(raw_data$correct==1, 0, 1))
# define the values for the rewards
value <- ifelse(raw_data$correct==1, 1, 0)
## all RT with negative choices -> -1
#new_RT <- ifelse(raw_data$correct==1, raw_data$RT*-1, raw_data$RT)
## # obs
n_trials <- nrow(raw_data)
##
stims <- raw_data$aStim
# encoding for simulation: lower (incorrect) response=1, upper (correct) response =2
raw_data$response = raw_data$correct+1
raw_data$nonresponse = abs(raw_data$correct-2)
dat <- list("N" = n_subj, "T"=n_trials,"RTbound" = 0.15,"minRT" = minRT, "iter" = raw_data$trial, "response" = raw_data$response,"nonresponse" = raw_data$nonresponse,
"RT" = raw_data$RT, "first" = first, "last" = last, "value"=value, "stims" = stims)  # names list of numbers
stanmodel_invlog <- rstan::stan_model(model_path)
fit_invlog <- rstan::sampling(object  = stanmodel_invlog,
data    = dat,
init    = "random",
chains  = 2,
iter    = 4000,
warmup  = 1000,
thin    = 1,
control = list(adapt_delta   = 0.95,
stepsize      = 1,
max_treedepth = 10),
verbose =TRUE)
parValsinvl <- rstan::extract(fit_invlog, permuted = TRUE)
parValsinvl <- rstan::extract(fit_invlog, permuted = TRUE)
mes
## now access the data of the fit
print(names(parVals))
fit_summary_invlog <- summary(fit_invlog)
print(fit_summary_invlog$summary)
print(names(fit_summary_invlog))
View(parValsinvl)
print(fit_summary_invlog$summary)
print(fit_summary_invlog)
fit_summary_invlog <- rstan::summary(fit_invlog)
print(fit_summary_invlog)
print(fit_summary_invlog$summary)
library(boot) #needed for inverse logit
inv.logit(1.46)
inv.logit(1.55)
logit(1.55)
v_mod <- 0.466160223
eta_pos <- 1.462815546
eta_neg <- 1.557359404
alpha <- 1.576948527
a_mod <- 0.077043196
tau <- 0.673802435
ev <- matrix(data=0, nrow=dat$T,ncol=2)
pe <- list()
pe <- rep(0,dat$T)
delta <- list()
delta <- rep(0,dat$T)
for(s in 1:dat$N){
# initialize lower(=1) and upper(=2) bound value
ev[first[s],1] <- 0.5
ev[first[s],2] <- 0.5
for(trial in (first[s]:(last[s]-1))){
delta[trial] <- (ev[trial,2]-ev[trial,1]) * v_mod
if(dat$response[trial]==1){
ev[trial+1,1] <- ev[trial,1] + inv.logit(eta_neg) * (dat$value[trial]-ev[trial,1])
ev[trial+1,2] <- ev[trial,2]
}
else{
ev[trial+1,2] <- ev[trial,2] + inv.logit(eta_pos) * (dat$value[trial]-ev[trial,2])
ev[trial+1,1] <- ev[trial,1]
}
delta[last[s]] =  (ev[last[s]-1,2]-ev[last[s]-1,1]) * v_mod
}
}
learning <- cbind(ev,dat$response,delta)
learning
View(dat)
ev <- matrix(data=0, nrow=dat$T,ncol=2)
pe <- list()
pe <- rep(0,dat$T)
delta <- list()
delta <- rep(0,dat$T)
for(s in 1:dat$N){
# initialize lower(=1) and upper(=2) bound value
ev[first[s],1] <- 0.5
ev[first[s],2] <- 0.5
for(trial in (first[s]:(last[s]-1))){
delta[trial] <- (ev[trial,2]-ev[trial,1]) * v_mod
if(dat$response[trial]==1){
ev[trial+1,1] <- ev[trial,1] + inv.logit(eta_neg) * (dat$value[trial]-ev[trial,1])
ev[trial+1,2] <- ev[trial,2]
}
if(dat$response[trial]==2){
ev[trial+1,2] <- ev[trial,2] + inv.logit(eta_pos) * (dat$value[trial]-ev[trial,2])
ev[trial+1,1] <- ev[trial,1]
}
delta[last[s]] =  (ev[last[s]-1,2]-ev[last[s]-1,1]) * v_mod
}
}
learning <- cbind(ev,dat$response,delta)
learning
View(dat)
View(dat)
View(dat)
path <- dirname(rstudioapi::getActiveDocumentContext()$path)
model_path <- paste0(path,"/rlddm_invlog.stan")
data_path <- paste0(path,"/test_input.txt")
setwd(path)
raw_data <- data.table::fread(file = data_path, header = TRUE, sep = "\t", data.table = TRUE,
fill = TRUE, stringsAsFactors = TRUE, logical01 = FALSE)
raw_data <- cbind(rep(substr(data_path,1,12),dim(raw_data)[1]),raw_data)
#D<-D[D$resp!=0,] # remove 'too slow ' responses
### Rename and transform some columns
colnames(raw_data)[1] <- "subjID"
raw_data$rt <- raw_data$rt/1000
names(raw_data)[names(raw_data)=="rt"] <- "RT"
# automatically filter missed responses (since RT = 0)
raw_data <- raw_data[which(raw_data$RT > 0.15),]
raw_data$subjID = rep('01',nrow(raw_data))
# fb = 0 incorrect, fb = 1 correct, (fb = 2 missed)
names(raw_data)[names(raw_data)=="fb"] <- "correct"
## prepare data for jags
#raw_data$row <- seq.int(nrow(raw_data))
DT_trials <- raw_data[, .N, by = "subjID"]
subjs     <- DT_trials$subjID
n_subj    <- length(subjs)
# get minRT
minRT <- with(raw_data, aggregate(RT, by = list(y = subjID), FUN = min)[["x"]])
ifelse(is.null(dim(minRT)),minRT<-as.array(minRT))
# assign new trial number for excluded decisions
for (subj in subjs){
sub <- which(raw_data$subjID==subj)
raw_data[sub,]$trial <- seq.int(nrow(raw_data[sub,]))
}
# first is Sx1 matrix identifying all first trials of a subject for each choice
first <- which(raw_data$trial==1)
# if N=1 transform int to 1-d array
ifelse(is.null(dim(first)),first<-as.array(first))
# last is a Sx1 matrix identifying all last trials of a subject for each choice
last <- as.integer(first + DT_trials$N - 1)
ifelse(is.null(dim(last)),last<-as.array(last))
# incorrect is the inverse vector of choice and is needed to update the ev for the non-choices
raw_data$incorrect <- as.integer(ifelse(raw_data$correct==1, 0, 1))
# define the values for the rewards
value <- ifelse(raw_data$correct==1, 1, 0)
## all RT with negative choices -> -1
#new_RT <- ifelse(raw_data$correct==1, raw_data$RT*-1, raw_data$RT)
## # obs
n_trials <- nrow(raw_data)
##
stims <- raw_data$aStim
# encoding for simulation: lower (incorrect) response=1, upper (correct) response =2
raw_data$response = raw_data$correct+1
raw_data$nonresponse = abs(raw_data$correct-2)
dat <- list("N" = n_subj, "T"=n_trials,"RTbound" = 0.15,"minRT" = minRT, "iter" = raw_data$trial, "response" = raw_data$response,"nonresponse" = raw_data$nonresponse,
"RT" = raw_data$RT, "first" = first, "last" = last, "value"=value, "stims" = stims)  # names list of numbers
stanmodel_invlog <- rstan::stan_model(model_path)
fit_invlog <- rstan::sampling(object  = stanmodel_invlog,
data    = dat,
init    = "random",
chains  = 2,
iter    = 10000,
warmup  = 2000,
thin    = 1,
control = list(adapt_delta   = 0.9,
stepsize      = 1,
max_treedepth = 10),
verbose =TRUE)
parValsinvl <- rstan::extract(fit_invlog, permuted = TRUE)
fit_summary_invlog <- rstan::summary(fit_invlog)
print(fit_summary_invlog$summary)
v_mod <- 0.004885427
eta_pos <- 1.687821991
eta_neg <- 0.192118828
alpha <- 1.516379240
a_mod <- 0.069487627
tau <- 0.681932623
ev <- matrix(data=0, nrow=dat$T,ncol=2)
pe <- list()
pe <- rep(0,dat$T)
delta <- list()
delta <- rep(0,dat$T)
for(s in 1:dat$N){
# initialize lower(=1) and upper(=2) bound value
ev[first[s],1] <- 0.5
ev[first[s],2] <- 0.5
for(trial in (first[s]:(last[s]-1))){
delta[trial] <- (ev[trial,2]-ev[trial,1]) * v_mod
if(dat$response[trial]==1){
ev[trial+1,1] <- ev[trial,1] - inv.logit(eta_neg) * (dat$value[trial]-ev[trial,1])
ev[trial+1,2] <- ev[trial,2]
}
if(dat$response[trial]==2){
ev[trial+1,2] <- ev[trial,2] + inv.logit(eta_pos) * (dat$value[trial]-ev[trial,2])
ev[trial+1,1] <- ev[trial,1]
}
delta[last[s]] =  (ev[last[s]-1,2]-ev[last[s]-1,1]) * v_mod
}
}
learning <- cbind(ev,dat$response,delta)
learning
ev <- matrix(data=0, nrow=dat$T,ncol=2)
pe <- list()
pe <- rep(0,dat$T)
delta <- list()
delta <- rep(0,dat$T)
for(s in 1:dat$N){
# initialize lower(=1) and upper(=2) bound value
ev[first[s],1] <- 0.5
ev[first[s],2] <- 0.5
for(trial in (first[s]:(last[s]-1))){
delta[trial] <- (ev[trial,2]-ev[trial,1]) * v_mod
if(dat$response[trial]==1){
ev[trial+1,1] <- ev[trial,1] - (inv.logit(eta_neg) * (dat$value[trial]-ev[trial,1]))
ev[trial+1,2] <- ev[trial,2]
}
if(dat$response[trial]==2){
ev[trial+1,2] <- ev[trial,2] + (inv.logit(eta_pos) * (dat$value[trial]-ev[trial,2]))
ev[trial+1,1] <- ev[trial,1]
}
delta[last[s]] =  (ev[last[s]-1,2]-ev[last[s]-1,1]) * v_mod
}
}
learning <- cbind(ev,dat$response,delta)
learning
View(dat)
.libPaths()
assign(".lib.loc", "C:/Program Files/R/R-3.5.2/library", envir = environment(.libPaths))
#install.packages("rstan", lib="C:\\Program Files\\R\\R-3.5.2\\library")
#install.packages("StanHeaders", lib="C:\\Program Files\\R\\R-3.5.2\\library")
#install.packages("rstantools", lib="C:\\Program Files\\R\\R-3.5.2\\library")
#install.packages("hBayesDM", lib="C:\\Program Files\\R\\R-3.5.2\\library")
#install.packages("Rcpp", lib="C:\\Program Files\\R\\R-3.5.2\\library")
# after successful installation, load required packages
library("StanHeaders", lib.loc="C:/Program Files/R/R-3.5.2/library")
library("rstan", lib.loc="C:/Program Files/R/R-3.5.2/library")
library("Rcpp", lib.loc="C:/Program Files/R/R-3.5.2/library")
library("hBayesDM", lib.loc="C:/Program Files/R/R-3.5.2/library")
path <- dirname(rstudioapi::getActiveDocumentContext()$path)
model_path <- paste0(path,"/rlddm_invlog.stan")
data_path <- paste0(path,"/test_input.txt")
setwd(path)
raw_data <- data.table::fread(file = data_path, header = TRUE, sep = "\t", data.table = TRUE,
fill = TRUE, stringsAsFactors = TRUE, logical01 = FALSE)
raw_data <- cbind(rep(substr(data_path,1,12),dim(raw_data)[1]),raw_data)
#D<-D[D$resp!=0,] # remove 'too slow ' responses
### Rename and transform some columns
colnames(raw_data)[1] <- "subjID"
raw_data$rt <- raw_data$rt/1000
names(raw_data)[names(raw_data)=="rt"] <- "RT"
# automatically filter missed responses (since RT = 0)
raw_data <- raw_data[which(raw_data$RT > 0.15),]
raw_data$subjID = rep('01',nrow(raw_data))
# fb = 0 incorrect, fb = 1 correct, (fb = 2 missed)
names(raw_data)[names(raw_data)=="fb"] <- "correct"
## prepare data for jags
#raw_data$row <- seq.int(nrow(raw_data))
DT_trials <- raw_data[, .N, by = "subjID"]
subjs     <- DT_trials$subjID
n_subj    <- length(subjs)
# get minRT
minRT <- with(raw_data, aggregate(RT, by = list(y = subjID), FUN = min)[["x"]])
ifelse(is.null(dim(minRT)),minRT<-as.array(minRT))
# assign new trial number for excluded decisions
for (subj in subjs){
sub <- which(raw_data$subjID==subj)
raw_data[sub,]$trial <- seq.int(nrow(raw_data[sub,]))
}
# first is Sx1 matrix identifying all first trials of a subject for each choice
first <- which(raw_data$trial==1)
# if N=1 transform int to 1-d array
ifelse(is.null(dim(first)),first<-as.array(first))
# last is a Sx1 matrix identifying all last trials of a subject for each choice
last <- as.integer(first + DT_trials$N - 1)
ifelse(is.null(dim(last)),last<-as.array(last))
# incorrect is the inverse vector of choice and is needed to update the ev for the non-choices
raw_data$incorrect <- as.integer(ifelse(raw_data$correct==1, 0, 1))
# define the values for the rewards
value <- ifelse(raw_data$correct==1, 1, 0)
## all RT with negative choices -> -1
#new_RT <- ifelse(raw_data$correct==1, raw_data$RT*-1, raw_data$RT)
## # obs
n_trials <- nrow(raw_data)
##
stims <- raw_data$aStim
# encoding for simulation: lower (incorrect) response=1, upper (correct) response =2
raw_data$response = raw_data$correct+1
raw_data$nonresponse = abs(raw_data$correct-2)
dat <- list("N" = n_subj, "T"=n_trials,"RTbound" = 0.15,"minRT" = minRT, "iter" = raw_data$trial, "response" = raw_data$response,"nonresponse" = raw_data$nonresponse,
"RT" = raw_data$RT, "first" = first, "last" = last, "value"=value, "stims" = stims)  # names list of numbers
stanmodel_invlog <- rstan::stan_model(model_path)
fit_invlog <- rstan::sampling(object  = stanmodel_invlog,
data    = dat,
init    = "random",
chains  = 2,
iter    = 10000,
warmup  = 2000,
thin    = 1,
control = list(adapt_delta   = 0.9,
stepsize      = 1,
max_treedepth = 10),
verbose =TRUE)
parValsinvl <- rstan::extract(fit_invlog, permuted = TRUE)
parValsinvl
fit_summary_invlog <- rstan::summary(fit_invlog)
print(fit_summary_invlog$summary)
inv.logit(1.44)
inv.losig(1.64)
inv.logit(1.64)
v_mod <- 0.004885427
eta_pos <- 1.687821991
eta_neg <- 0.192118828
alpha <- 1.516379240
a_mod <- 0.069487627
tau <- 0.681932623
ev <- matrix(data=0, nrow=dat$T,ncol=2)
pe <- list()
pe <- rep(0,dat$T)
delta <- list()
delta <- rep(0,dat$T)
for(s in 1:dat$N){
# initialize lower(=1) and upper(=2) bound value
ev[first[s],1] <- 0.5
ev[first[s],2] <- 0.5
for(trial in (first[s]:(last[s]-1))){
delta[trial] <- (ev[trial,2]-ev[trial,1]) * v_mod
if(dat$response[trial]==1){
ev[trial+1,1] <- ev[trial,1] + (inv.logit(eta_neg) * (dat$value[trial]-ev[trial,1]))
ev[trial+1,2] <- ev[trial,2]
}
if(dat$response[trial]==2){
ev[trial+1,2] <- ev[trial,2] + (inv.logit(eta_pos) * (dat$value[trial]-ev[trial,2]))
ev[trial+1,1] <- ev[trial,1]
}
delta[last[s]] =  (ev[last[s]-1,2]-ev[last[s]-1,1]) * v_mod
}
}
learning
learning <- cbind(ev,dat$response,delta)
learning
